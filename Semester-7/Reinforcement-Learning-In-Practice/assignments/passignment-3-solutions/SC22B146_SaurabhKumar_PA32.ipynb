{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19fc93e",
   "metadata": {},
   "source": [
    "### Programming Assignment 3 - Part II\n",
    "##### Submitted By: Saurabh Kumar (SC22B146)\n",
    "#### Solution of the \"Clinical Decision Making Problem [Puterman]\" and study of optimal policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3795c",
   "metadata": {},
   "source": [
    "**Assumtion:** H = 2, L = 2  \n",
    "  \n",
    "**Probabilities:**  \n",
    "gamma(h'|h) : the probability that a patient in health state h deteriorates to state h  \n",
    "delta(h) : the probability a patient in health state h dies from liver failure prior to the next decision epoch  \n",
    "beta (l|h) : the probability that a patient in health state h is offered a liver of quality  \n",
    "phi(h) : the probability a patient in health state h is not o!ered a liver prior to the next decision epoch  \n",
    "\n",
    "**Given that:**  \n",
    "gamma(1∣1) = 0.8, gamma(2∣1) = 0.1,  gamma(1∣2) = 0, gamma(2∣2) = 0.6  \n",
    "beta(1∣1) = 0.2, beta(2∣1) = 0.5,  beta(1∣2) = 0.3, beta(2∣2) = 0.5  \n",
    "R(1∣1) = 5, R(2∣1) = 2,  R(1∣2) = 3, R(2∣2) = 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f4e6e",
   "metadata": {},
   "source": [
    "**Write down what would be delta(1) and delta(2)?**  \n",
    "For health state h = 1,  \n",
    "gamma(1∣1)+gamma(2∣1)+delta(1)=1  \n",
    "This gives, delta(1) = 0.1  \n",
    "\n",
    "For health state h = 2,  \n",
    "gamma(1∣2)+gamma(2∣2)+delta(2)=1  \n",
    "This gives, delta(2) = 0.4  \n",
    "\n",
    "**Write down what would be phi(1) and phi(2)?**  \n",
    "For health state h = 1,  \n",
    "beta(1∣1)+beta(2∣1)+phi(1)=1  \n",
    "This gives, phi(1) = 0.3  \n",
    "\n",
    "For health state h = 2,  \n",
    "beta(1∣2)+beta(2∣2)+phi(2)=1  \n",
    "This gives, phi(2) = 0.2  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bcd509",
   "metadata": {},
   "source": [
    "**Discount Factor**  \n",
    "For this problem, the discount factor is **1**. This is because the model has **absorbing states** - death (delta) and post-transplant (tau). Any policy will eventually lead to one of these states, ending the process. Unlike typical infinite-horizon problems that require a discount factor less than 1 to ensure rewards don't go to infinity, this problem's structure guarantees a finite total reward. Therefore, we can maximize the undiscounted life expectancy by setting the discount factor to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e53ece",
   "metadata": {},
   "source": [
    "**Transition Probabilities p(j|s,a)**  \n",
    "The transition probability p(j|s, a) is the chance of moving from a current state s to a next state j by taking action a. \n",
    "   \n",
    "**Action a0 (Wait/Reject):** If wait, the transition probability is the product of two independent events: the change in health and the status of a new liver offer.  \n",
    "The probability of moving from s=(h,l) to j=(h', l') is gamma(h'|h) * betta(l'|h).  \n",
    "The probability of dying is delta(h).\n",
    "\n",
    "\n",
    "**Action a1 (Accept):** If accept a liver, the transition is deterministic.  \n",
    "We move to the post-transplant state tau with a probability of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8288416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "State (Health=1, Liver=1): Wait/Reject\n",
      "State (Health=1, Liver=2): Wait/Reject\n",
      "State (Health=2, Liver=1): Accept\n",
      "State (Health=2, Liver=2): Wait/Reject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Model Parameters\n",
    "gamma = np.array([[0.8, 0.1], [0.0, 0.6]]) # Health deterioration probabilities\n",
    "beta = np.array([[0.2, 0.5], [0.3, 0.5]]) # Liver offer probabilities\n",
    "R_hl = np.array([[5, 3], [2, 1]]) # Post-transplant rewards\n",
    "delta = np.array([0.1, 0.4]) # Death probabilities\n",
    "phi = np.array([0.3, 0.2]) # No-offer probabilities\n",
    "\n",
    "# MDP\n",
    "state_map = {\n",
    "    (1, 1): 0, (1, 2): 1, (1, 'phi1'): 2,\n",
    "    (2, 1): 3, (2, 2): 4, (2, 'phi1'): 5,\n",
    "    'delta1': 6, 'tau1': 7\n",
    "}\n",
    "inv_state_map = {v: k for k, v in state_map.items()}\n",
    "num_states, num_actions = 8, 2\n",
    "P = np.zeros((num_actions, num_states, num_states))\n",
    "R = np.zeros((num_actions, num_states))\n",
    "\n",
    "# Transition and Reward Matrices\n",
    "for s_idx, state in inv_state_map.items():\n",
    "    if state in ['delta1', 'tau1']:\n",
    "        P[0, s_idx, s_idx] = 1.0\n",
    "        continue\n",
    "    h, l = state\n",
    "    # Action 0: wait/reject\n",
    "    R[0, s_idx] = 1.0 - delta[h-1]\n",
    "    for h_prime in range(h, 3):\n",
    "        prob_h = gamma[h-1, h_prime-1]\n",
    "        for l_prime in range(1, 3):\n",
    "            P[0, s_idx, state_map[(h_prime, l_prime)]] += prob_h * beta[h_prime-1, l_prime-1]\n",
    "        P[0, s_idx, state_map[(h_prime, 'phi1')]] += prob_h * phi[h_prime-1]\n",
    "    P[0, s_idx, state_map['delta1']] = delta[h-1]\n",
    "    # Action 1: accept\n",
    "    if l != 'phi1':\n",
    "        R[1, s_idx] = R_hl[h-1, l-1]\n",
    "        P[1, s_idx, state_map['tau1']] = 1.0\n",
    "\n",
    "# Value Iteration\n",
    "V = np.zeros(num_states)\n",
    "for i in range(100):\n",
    "    V_old = V.copy()\n",
    "    Q = R + 1.0 * (P @ V_old)\n",
    "    invalid_states = [2, 5, 6, 7]\n",
    "    Q[1, invalid_states] = -np.inf\n",
    "    V = np.max(Q, axis=0)\n",
    "    if np.max(np.abs(V - V_old)) < 1e-6:\n",
    "        break\n",
    "\n",
    "# Optimal Policy\n",
    "policy = np.argmax(Q, axis=0)\n",
    "action_map = {0: 'Wait/Reject', 1: 'Accept'}\n",
    "print(\"Optimal Policy:\")\n",
    "for s_idx, state in inv_state_map.items():\n",
    "    if isinstance(state, tuple) and state[1] != 'phi1':\n",
    "        action = action_map[policy[s_idx]]\n",
    "        print(f\"State (Health={state[0]}, Liver={state[1]}): {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6979df3",
   "metadata": {},
   "source": [
    "**Optimal Policy**\n",
    "The optimal policy dictates the best action to take in each state to maximize the expected total life expectancy. The calculated optimal policy is:  \n",
    "State (Health=1, Liver Quality=1): Wait/Reject  \n",
    "State (Health=1, Liver Quality=2): Wait/Reject  \n",
    "State (Health=2, Liver Quality=1): Accept  \n",
    "State (Health=2, Liver Quality=2): Wait/Reject  \n",
    "\n",
    " \n",
    "This policy shows that a healthy patient should wait for a high-quality organ, but an unhealthy patient should accept any available organ because the risk of waiting is too high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
