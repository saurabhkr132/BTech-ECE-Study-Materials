{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Visual Scene Recognition System\n",
    "\n",
    "In this assignment, we will implement a visual scene recognition system using the Bag-of-Visual-Words (BoVW) model. The system comprises three main components:\n",
    "\n",
    "    Convert Image to Word Map\n",
    "    Use a precomputed visual dictionary (e.g., obtained by clustering SIFT descriptors or filter responses) and assign each pixel or keypoint in an image to its closest visual word.\n",
    "\n",
    "    Get Image Features\n",
    "    From the word map, compute a histogram (or other feature vector) that represents the image’s visual content.\n",
    "\n",
    "    Build Recognition System – Nearest Neighbors\n",
    "    Build a scene classifier using a nearest neighbors approach where images are classified based on the similarity of their feature histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Convert Image to Word Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_wordmap(image: np.ndarray, dictionary: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given an image and a visual dictionary, convert the image into a word map.\n",
    "    \n",
    "    For each pixel (or keypoint region), extract a feature vector (e.g., raw pixel intensities,\n",
    "    filter responses, or SIFT features) and then assign it to the nearest visual word (dictionary entry).\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (RGB) as a numpy array.\n",
    "        dictionary: A 2D numpy array where each row is a visual word (centroid).\n",
    "    \n",
    "    Returns:\n",
    "        wordmap: A 2D numpy array with the same spatial dimensions as the input image, where each value \n",
    "                 corresponds to the index of the nearest visual word.\n",
    "    \"\"\"\n",
    "    # Convert image to grayscale (or use any other feature extraction method)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # TODO: Extract features for each pixel or keypoint.\n",
    "    # For simplicity, you may use small patches around each pixel.\n",
    "    # For example, you could use a sliding window to get patches and then flatten them.\n",
    "    # Here, we provide a very basic pixel intensity as the \"feature\".\n",
    "    features = gray.reshape(-1, 1)  # Shape: (H*W, 1)\n",
    "    \n",
    "    # TODO: Compute the distance between each feature and each word in the dictionary.\n",
    "    # Hint: You can use np.linalg.norm or np.sum((features - dictionary)**2, axis=1) for each feature.\n",
    "    \n",
    "    H, W = gray.shape\n",
    "    wordmap = np.zeros((H * W,), dtype=int)\n",
    "    for i in range(features.shape[0]):\n",
    "        # Compute distances between feature i and each word in the dictionary.\n",
    "        # TODO: Replace the line below with your distance computation.\n",
    "        distances = np.linalg.norm(dictionary - features[i], axis=1)\n",
    "        # TODO: Assign the index of the nearest word to wordmap.\n",
    "        wordmap[i] = np.argmin(distances)\n",
    "    \n",
    "    wordmap = wordmap.reshape(H, W)\n",
    "    return wordmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Get Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(wordmap: np.ndarray, dict_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the histogram of visual words for the given wordmap.\n",
    "    \n",
    "    Args:\n",
    "        wordmap: 2D numpy array where each element is an index of a visual word.\n",
    "        dict_size: The number of visual words (size of the dictionary).\n",
    "        \n",
    "    Returns:\n",
    "        feature_hist: 1D numpy array of normalized histogram counts with length dict_size.\n",
    "    \"\"\"\n",
    "    # TODO: Compute the histogram of visual words in the wordmap.\n",
    "    hist, _ = np.histogram(wordmap, bins=np.arange(dict_size + 1))\n",
    "    \n",
    "    # TODO: Normalize the histogram.\n",
    "    feature_hist = hist.astype(float) / (np.sum(hist) + 1e-6)\n",
    "    \n",
    "    return feature_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Build Recognition System - Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recognition_system(train_features: np.ndarray, train_labels: np.ndarray) -> Any:\n",
    "    \"\"\"\n",
    "    Build a recognition system using a nearest neighbors classifier.\n",
    "    \n",
    "    Args:\n",
    "        train_features: 2D numpy array where each row is an image feature histogram.\n",
    "        train_labels: 1D numpy array of labels corresponding to the training images.\n",
    "        \n",
    "    Returns:\n",
    "        knn: Trained nearest neighbors classifier.\n",
    "    \"\"\"\n",
    "    # TODO: Create and train a KNeighborsClassifier from scikit-learn.\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(train_features, train_labels)\n",
    "    return knn\n",
    "\n",
    "def evaluate_recognition_system(knn: Any, test_features: np.ndarray, test_labels: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate the recognition system and print accuracy and confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        knn: The trained nearest neighbors classifier.\n",
    "        test_features: 2D numpy array of test image features.\n",
    "        test_labels: 1D numpy array of test image labels.\n",
    "    \"\"\"\n",
    "    # TODO: Predict labels for the test set using the trained classifier.\n",
    "    pred_labels = knn.predict(test_features)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = np.mean(pred_labels == test_labels)\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    # TODO: Optionally, compute and display the confusion matrix.\n",
    "    # You can use sklearn.metrics.confusion_matrix for this.\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(test_labels, pred_labels)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "src_dir = 'dataset/caltech-101/caltech-101/101_ObjectCategories'\n",
    "train_dir = 'dataset/caltech-101/caltech-101/train'\n",
    "test_dir = 'dataset/caltech-101/caltech-101/test'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for category in os.listdir(src_dir):\n",
    "    src_category_path = os.path.join(src_dir, category)\n",
    "    if not os.path.isdir(src_category_path) or category == 'BACKGROUND_Google':\n",
    "        continue\n",
    "\n",
    "    files = [f for f in os.listdir(src_category_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    random.shuffle(files)\n",
    "    split_idx = int(len(files) * 0.8)\n",
    "\n",
    "    train_files = files[:split_idx]\n",
    "    test_files = files[split_idx:]\n",
    "\n",
    "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n",
    "\n",
    "    for f in train_files:\n",
    "        shutil.copy(os.path.join(src_category_path, f), os.path.join(train_dir, category, f))\n",
    "    for f in test_files:\n",
    "        shutil.copy(os.path.join(src_category_path, f), os.path.join(test_dir, category, f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tests to verify the implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dictionary with 100 visual words\n",
      "Accuracy: 13.05%\n",
      "Confusion Matrix:\n",
      "[[  4   0   0 ...   0   0   0]\n",
      " [  0 149   0 ...   0   0   0]\n",
      " [  0   5   0 ...   0   0   0]\n",
      " ...\n",
      " [  0  10   0 ...   0   0   0]\n",
      " [  0   8   0 ...   0   0   0]\n",
      " [  0   6   0 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"dataset/caltech-101/caltech-101/train\"\n",
    "test_dir = \"dataset/caltech-101/caltech-101/test\"\n",
    "\n",
    "# For this example, assume dictionary is precomputed. \n",
    "# In a full system, you would extract features from training images and run k-means.\n",
    "dict_size = 50  # Example dictionary size\n",
    "# TODO: Load or compute your visual dictionary.\n",
    "# Here, we randomly initialize a dummy dictionary.\n",
    "\n",
    "# dictionary = np.random.rand(dict_size, 1)\n",
    "dictionary = np.load(\"dictionary.npy\")\n",
    "dict_size = dictionary.shape[0]\n",
    "print(f\"Loaded dictionary with {dict_size} visual words\")\n",
    "\n",
    "\n",
    "# Process training images\n",
    "train_features = []\n",
    "train_labels = []\n",
    "train_classes = os.listdir(train_dir)  # each subfolder is a class\n",
    "for label, cls in enumerate(train_classes):\n",
    "    cls_dir = os.path.join(train_dir, cls)\n",
    "    for filename in os.listdir(cls_dir):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            img_path = os.path.join(cls_dir, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            wordmap = convert_image_to_wordmap(image, dictionary)\n",
    "            feat = get_image_features(wordmap, dict_size)\n",
    "            train_features.append(feat)\n",
    "            train_labels.append(label)\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Build recognition system\n",
    "knn = build_recognition_system(train_features, train_labels)\n",
    "\n",
    "# Process test images\n",
    "test_features = []\n",
    "test_labels = []\n",
    "test_classes = os.listdir(test_dir)\n",
    "for label, cls in enumerate(test_classes):\n",
    "    cls_dir = os.path.join(test_dir, cls)\n",
    "    for filename in os.listdir(cls_dir):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            img_path = os.path.join(cls_dir, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            wordmap = convert_image_to_wordmap(image, dictionary)\n",
    "            feat = get_image_features(wordmap, dict_size)\n",
    "            test_features.append(feat)\n",
    "            test_labels.append(label)\n",
    "            \n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Evaluate recognition system\n",
    "evaluate_recognition_system(knn, test_features, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
